@InProceedings{10.1007/978-3-031-18523-6_8,
author="Dalmaz, Onat
and Mirza, Usama
and Elmas, G{\"o}kberk
and {\"O}zbey, Muzaffer
and Dar, Salman U. H.
and {\c{C}}ukur, Tolga",
editor="Albarqouni, Shadi
and Bakas, Spyridon
and Bano, Sophia
and Cardoso, M. Jorge
and Khanal, Bishesh
and Landman, Bennett
and Li, Xiaoxiao
and Qin, Chen
and Rekik, Islem
and Rieke, Nicola
and Roth, Holger
and Sheet, Debdoot
and Xu, Daguang",
title="A Specificity-Preserving Generative Model forÂ Federated MRI Translation",
booktitle="Distributed, Collaborative, and Federated Learning, and Affordable AI and Healthcare for Resource Diverse Global Health",
year="2022",
publisher="Springer Nature Switzerland",
address="Cham",
pages="79--88",
abstract="MRI translation models learn a mapping from an acquired source contrast to an unavailable target contrast. Collaboration between institutes is essential to train translation models that can generalize across diverse datasets. That said, aggregating all imaging data and training a centralized model poses privacy problems. Recently, federated learning (FL) has emerged as a collaboration framework that enables decentralized training to avoid sharing of imaging data. However, FL-trained translation models can deteriorate by the inherent heterogeneity in the distribution of MRI data. To improve reliability against domain shifts, here we introduce a novel specificity-preserving FL method for MRI contrast translation. The proposed approach is based on an adversarial model that adaptively normalizes the feature maps across the generator based on site-specific latent variables. Comprehensive FL experiments were conducted on multi-site datasets to show the effectiveness of the proposed approach against prior federated methods in MRI contrast translation.",
isbn="978-3-031-18523-6"
}
